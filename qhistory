#!/usr/bin/env python

import sys
import argparse
from glob import glob
from torque_accounting import parser
import pprint
import re
from datetime import datetime, timedelta

# For bytes_to_human()
from math import log

global printfmt
printfmt = "%10s %10s  %7s  %5s  %19s  %12s %12s"
debug = 0


def print_job(name,job):
    try:
        jid = (name[:8]+"..") if len(name)>10 else name
        user=job['user']
        user = (user[:8]+"..") if len(user)>10 else user
        queue = job['queue']
        queue = (queue[:5]+"..") if len(queue)>7 else queue
        queuet=job['events']['Q']
        start=job['events']['S']
        endt=job['events']['E']
        wait_time=job['wait_time']
        run_time=job['run_time']
        nodect=job['Resource_List.nodect']
        #nodect2=job['Resource_List.ncpus'] 
       #print printfmt % (jid,user,queue,nodect,queuet,start,endt,wait_time,run_time)
        print printfmt % (jid,user,queue,nodect,start,wait_time,run_time)
    except KeyError:
	pass

def filter_by_user(username,jobs):
    ujobs={}
    for j in jobs:
        try:
            if jobs[j]['user']==username:
                ujobs[j]=jobs[j]
        except KeyError:
            #print "This user has an error" + username
	    pass
	    
    return ujobs

def filter_by_queue(queue,jobs):
    qjobs={}
    for j in jobs:
        try:
            if jobs[j]['queue']==queue:
                qjobs[j]=jobs[j]
        except KeyError:
            pass
    return qjobs

def print_nodes(job):
    try:
        print "%s\n" % (job['exec_host'])
    except KeyError:
        print "This job has no exec_host information!"

def print_header():
    print printfmt % ("Job ID","Username","Queue","Nodes", "Start Time","Waiting","Running")
    print printfmt % ("======","========","=====","=====", "==========","=======","=======")

def print_full_job(jobid,jobs):
    for j in jobs:
        if j==jobid or re.match("%s." % (jobid),j):
            pp=pprint.PrettyPrinter(indent=4)
            print "%s:" % (j)
            pp.pprint(jobs[j])
            break

def jobname_to_int(jobname):
    return int(jobname.split('.')[0])

def exechost_to_nodes(exec_host_string):
    nodes=set()
    ehosts=exec_host_string.split('+')
    for eh in ehosts:
        nodes.add(eh.split('/')[0])
    return nodes

def exechost_to_procs(exec_host_string):
    return len(exec_host_string.split('+'))

def proplist_to_props(proplist):
    properties=set()
    props=proplist.split(':')
    for p in props:
        if not p.isdigit():
            properties.add(p)
    return properties

# Loosely based on a comment from here:
# http://stackoverflow.com/questions/1094841/reusable-library-to-get-human-readable-version-of-file-size
def bytes_to_human(num):
    """Human friendly file size"""
    unit_list = zip(['bytes', 'kB', 'MB', 'GB', 'TB', 'PB'], [0, 0, 1, 2, 2, 2])
    if num > 1:
        exponent = min(int(log(num, 1024)), len(unit_list) - 1)
        quotient = float(num) / 1024**exponent
        unit, num_decimals = unit_list[exponent]
        format_string = '{:.%sf} {}' % (num_decimals)
        return format_string.format(quotient, unit)
    if num == 0:
        return '0 bytes'
    if num == 1:
        return '1 byte'

# Loosely based on a comment from here:
# http://stackoverflow.com/questions/13343700/bytes-to-human-readable-and-back-without-data-loss
def human_to_bytes(size):
    """Convert human data value to bytes"""
    symbols = ('B', 'K', 'M', 'G', 'T', 'P')
    unit = size[-1:].strip().upper()
    if unit == "B":
     # Strip off trailing 'b' and see if we've got another unit
     size = size[:-1]
     unit = size[-1:].strip().upper()
     if unit in symbols:
      num = size[:-1]
     else:
      unit = "B"
      num = size
    else:
     # Assume size in bytes if no units specified?
     unit = "B"
     num = size
    assert num.isdigit() and unit in symbols
    num = float(num)
    prefix = {symbols[0]:1}
    for i, size in enumerate(symbols[1:]):
     prefix[size] = 1 << (i+1)*10
    return int(num * prefix[unit])
        

def print_summary(jobs, nodestats):
    users={}
    nodes={}
    properties={}
    queues={}
    mem_per_core_count={}
    alljobs=len(jobs)
    jobs_complete=0
    serial_jobs_complete=0
    shared_jobs_complete=0
    total_job_time=timedelta(0)
    total_node_hours=timedelta(0)
    total_nodes_used = 0
    total_cpu_hours=timedelta(0)
    total_cpus_used = 0
    total_serial_cpu_hours=timedelta(0)
    total_shared_cpu_hours=timedelta(0)
    total_shared_cpus_used = 0
    total_wait_time=timedelta(0)
    total_memory_bytes_requested = 0
    total_serial_memory_bytes_requested = 0
    total_shared_memory_bytes_requested = 0

    for j in jobs:
        try:
            qtime=datetime.strptime(jobs[j]['events']['Q'],"%m/%d/%Y %H:%M:%S")
            start=datetime.strptime(jobs[j]['events']['S'],"%m/%d/%Y %H:%M:%S")
            finish=datetime.strptime(jobs[j]['events']['E'],"%m/%d/%Y %H:%M:%S")
        except:
            continue

        # DBG: Figure out number of cores based on exec_host
        procs=exechost_to_procs(jobs[j]['exec_host'])
        if debug==1:
            print "Procs " + str(procs)

        nodelist=exechost_to_nodes(jobs[j]['exec_host'])
        for n in nodelist:
            try:
                nodes[n]['job_count'] += 1
                nodes[n]['job_time'] += (finish-start)
            except KeyError:
                nodes[n] = {}
                nodes[n]['job_count'] = 1
                nodes[n]['job_time'] = finish-start
        try:
            props=proplist_to_props(jobs[j]['Resource_List.neednodes'])
            for p in props:
                try:
                    properties[p] += 1
                    if debug==1:
                     print "Incrementing properties[" + p + "] = " + str(properties[p])
                except KeyError:
                    properties[p] = 1
                    if debug==1:
                     print "Setting properties[" + p + "] = 1"
        except KeyError:
            pass

        # DBG: Try and determine whether this is shared-mem or MPI
        shared_mem=0
        try:
         if "ppn" in jobs[j]['Resource_List.neednodes']:
          if int(jobs[j]['ppn']) > 1:
           if debug==1:
            print "Shared mem : ppn = " + jobs[j]['ppn']
           shared_mem=1
         if int(jobs[j]['Resource_List.tpn']) > 1:
          if debug==1:
           print "Shared mem : tpn = " + jobs[j]['Resource_List.tpn']
          shared_mem=1
        except KeyError:
         pass

        # Convert memory values to bytes
        jobs[j]['mem.qsub'] = human_to_bytes(jobs[j]['Resource_List.mem'])
        jobs[j]['mem_per_core'] = jobs[j]['mem.qsub'] / procs
        jobs[j]['mem.used'] = human_to_bytes(jobs[j]['resources_used.mem'])
        jobs[j]['vmem.used'] = human_to_bytes(jobs[j]['resources_used.vmem'])

        q=jobs[j]['queue']
        try:
            queues[q]['job_count'] += 1
            queues[q]['wait_time'] += (start-qtime)
        except KeyError:
            queues[q]={}
            queues[q]['job_count'] = 1
            queues[q]['wait_time'] = (start-qtime)
                
        u=jobs[j]['user']
        try:
            users[u]['job_count'] += 1
            if shared_mem==1:
             users[u]['shared_mem_count'] += 1
            users[u]['job_time'] += (finish-start)
            users[u]['node_time'] += int(jobs[j]['Resource_List.nodect'])*(finish-start)
            users[u]['node_total'] += int(jobs[j]['Resource_List.nodect'])
            users[u]['cpu_time'] += (procs)*(finish-start)
            users[u]['cpu_total'] += procs
            users[u]['wait_time'] += (start-qtime)
            users[u]['queues'].add(jobs[j]['queue'])
            try: 
                users[u]['requests'].append(jobs[j]['Resource_List.neednodes'])
            except:
                pass
        except KeyError:
            users[u]={}
            users[u]['job_count'] = 1
            if shared_mem==1:
             users[u]['shared_mem_count'] = 1
            users[u]['job_time'] = (finish-start)

            if not 'Resource_List.nodect' in jobs[j]:
             if debug==1:
              sys.stderr.write("WARNING: %s missing Resource_list.nodect\n" % j)
             print_job(j,jobs[j])
             jobs[j]['Resource_List.nodect']=1

            users[u]['node_time'] = int(jobs[j]['Resource_List.nodect'])*(finish-start)
            users[u]['node_total'] = int(jobs[j]['Resource_List.nodect'])
            users[u]['cpu_time'] = int(procs)*(finish-start)
            users[u]['cpu_total'] = procs
            users[u]['wait_time'] = (start-qtime)
            users[u]['queues'] = set()
            users[u]['queues'].add(jobs[j]['queue'])
            users[u]['requests'] = []
            try:
                users[u]['requests'].append(jobs[j]['Resource_List.neednodes'])
            except:
                pass

        jobs_complete += 1
        if procs==1:
         serial_jobs_complete += 1
         total_serial_cpu_hours += (finish-start)
         total_serial_memory_bytes_requested += int(jobs[j]['mem.qsub'])
        if shared_mem==1:
         shared_jobs_complete += 1
         total_shared_cpu_hours += (procs)*(finish-start)
         total_shared_cpus_used += procs
         total_shared_memory_bytes_requested += int(jobs[j]['mem.qsub'])
        total_job_time += (finish-start)
        total_nodes_used += int(jobs[j]['Resource_List.nodect'])
        total_node_hours += int(jobs[j]['Resource_List.nodect'])*(finish-start)
        total_cpu_hours += (procs)*(finish-start)
        total_cpus_used += procs
        total_wait_time += (start-qtime)
        total_memory_bytes_requested += int(jobs[j]['mem.qsub'])

      
        # DBG notes: Other useful fields (for determining memory
        # requested/used, GPUs, SM vs MPI, etc)
        # Resource_List.mem=15gb 
        # Resource_List.nodes=1:ppn=1 
        # Resource_List.partition=dmc 
        # resources_used.mem=1919948kb 
        # resources_used.vmem=1995544kb 

        # Waited more than 12 hours to start?
        if debug==1:
         if parser.strfdelta((start-qtime),"{hours}") > 43200:
            print "> 12 hours qtime: "
            try:
                print "nodes %s" % jobs[j]['Resource_List.neednodes']
            except:
                pass
            print ", mem %s" % jobs[j]['Resource_List.mem']
            try:
                print ", partition %s" % jobs[j]['Resource_List.partition']
            except:
                pass
            print "\n"

    print "-----------------------------"

    propfmt = "%8s - %6s"
    print propfmt % ("PROPERTY","COUNT")
    print propfmt % ("========","=====")
    for p in sorted(properties, key=lambda x: properties[x], reverse=True):
        print propfmt % (p, properties[p])
    print "-----------------------------"

    queuefmt = "%16s - %6s - %13s"
    print queuefmt % ("QUEUE","COUNT","AVG WAIT TIME")
    print queuefmt % ("============","======","=============")
    for q in sorted(queues, key=lambda x: queues[x], reverse=True):
     print queuefmt % (q, queues[q]['job_count'], 
         parser.strfdelta(queues[q]['wait_time']/queues[q]['job_count'],"{days}:{hours}:{minutes}:{seconds}"))
    print "-----------------------------"


    print "USERS"
    newfmt = "%15s - %4s - %10s - %10s - %13s - %13s - %13s"
    print newfmt % ("USER","JOBS","JOB TIME","NODE TIME","AVG WAIT TIME","AVG NODES/JOB","AVG CORES/JOB")
    print newfmt % ("====","====","========","=========","=============","=============","=============")
    for u in sorted(users, key=lambda x: users[x]['node_time'], reverse=True):
        print newfmt % ( u, str(users[u]['job_count']),
            parser.strfdelta(users[u]['job_time'],"{days}:{hours}:{minutes}:{seconds}"),
            parser.strfdelta(users[u]['node_time'],"{days}:{hours}:{minutes}:{seconds}"),
            #parser.strfdelta(users[u]['wait_time'],"{days}:{hours}:{minutes}:{seconds}"),
            parser.strfdelta( users[u]['wait_time']/users[u]['job_count'], "{days}:{hours}:{minutes}:{seconds}"),
            str( float(users[u]['node_total'])/users[u]['job_count'] ),
            str( float(users[u]['cpu_total'])/users[u]['job_count'] ) )
        print "\t\tQueues: %s" % ",".join(users[u]['queues'])
        if len(users[u]['requests'])>0:
            print "\t\tRequest types: %s" % " ; ".join(set(users[u]['requests']))
    print "-----------------------------"

    if nodestats:
        print "NODES"
        nodefmt = "%15s - %4s - %10s"
        print nodefmt % ("NODE","JOBS","JOB TIME")
        print nodefmt % ("====","====","========")
        for n in sorted(nodes, key=lambda x: nodes[x]['job_time'], reverse=True):
            print nodefmt % (n, str(nodes[n]['job_count']), 
            parser.strfdelta(nodes[n]['job_time'],"{days}:{hours}:{minutes}:{seconds}"))
        print " "
        print "-----------------------------"

    mpi_jobs_complete = (jobs_complete - serial_jobs_complete - shared_jobs_complete)
    total_mpi_cpus_used = (total_cpus_used - serial_jobs_complete - total_shared_cpus_used)
    total_mpi_memory_bytes_requested = (total_memory_bytes_requested - total_serial_memory_bytes_requested - total_shared_memory_bytes_requested)

    print " "
    print "Total jobs: %d" % alljobs
    print "Total jobs completed: %d (serial %d / MPI %d / SM %d)" % (jobs_complete, serial_jobs_complete, mpi_jobs_complete, shared_jobs_complete)
    print "Total job time: %s" % parser.strfdelta(total_job_time,"{days}:{hours}:{minutes}:{seconds}")
    print "Total node time used: %s" % parser.strfdelta(total_node_hours,"{days}:{hours}:{minutes}:{seconds}")
    print "Number of users: %d" % len(users)
    print "Number of nodes used: %d" % len(nodes)
    print "Number of cores used: %d (serial %d / MPI %d / SM %d)" % (total_cpus_used, serial_jobs_complete, total_mpi_cpus_used, total_shared_cpus_used)
    print " "
    print "Average nodes per job: %2.2f" % (float(total_nodes_used)/int(jobs_complete))
    if total_mpi_cpus_used > 0 and total_shared_cpus_used == 0:
    	print "Average cores per job: %2.2f (MPI %2.2f)" % ((float(total_cpus_used)/int(jobs_complete)), (float(total_mpi_cpus_used)/int(mpi_jobs_complete)))
    elif total_shared_cpus_used > 0 and total_mpi_cpus_used == 0:
    	print "Average cores per job: %2.2f (SM %2.2f)" % ((float(total_cpus_used)/int(jobs_complete)), (float(total_shared_cpus_used)/int(shared_jobs_complete)))
    elif total_mpi_cpus_used > 0 and total_shared_cpus_used > 0:
        print "Average cores per job: %2.2f (MPI %2.2f / SM %2.2f)" % ((float(total_cpus_used)/int(jobs_complete)), (float(total_mpi_cpus_used)/int(mpi_jobs_complete)), (float(total_shared_cpus_used)/int(shared_jobs_complete)))
    else:
	print "Average cores per job: %2.2f" % ((float(total_cpus_used)/int(jobs_complete)))

    print "Average wallclock time: %s" % parser.strfdelta( total_job_time/jobs_complete, "{days}:{hours}:{minutes}:{seconds}")
    print "Average node time: %s" % parser.strfdelta( total_node_hours/jobs_complete, "{days}:{hours}:{minutes}:{seconds}")
    print "Average cpu time: %s" % parser.strfdelta( total_cpu_hours/jobs_complete, "{days}:{hours}:{minutes}:{seconds}")
    print "Average waiting time: %s" % parser.strfdelta( total_wait_time/jobs_complete, "{days}:{hours}:{minutes}:{seconds}")
    print " "
    print "Total memory requested: %s (serial %s, MPI %s, SM %s)" % (bytes_to_human(total_memory_bytes_requested), bytes_to_human(total_serial_memory_bytes_requested), bytes_to_human(total_mpi_memory_bytes_requested), bytes_to_human(total_shared_memory_bytes_requested))
   
    if total_mpi_memory_bytes_requested > 0 and total_shared_memory_bytes_requested > 0 and total_serial_memory_bytes_requested > 0:
    	print "Average memory per job: %s (serial %s, MPI %s, SM %s)" % (bytes_to_human((float(total_memory_bytes_requested)/int(jobs_complete))), 
         bytes_to_human(float(total_serial_memory_bytes_requested)/int(serial_jobs_complete)),
       	 bytes_to_human(float(total_mpi_memory_bytes_requested)/int(mpi_jobs_complete)),
       	 bytes_to_human(float(total_shared_memory_bytes_requested)/int(shared_jobs_complete)))
        print "Average memory per core: %s (serial %s, MPI %s, SM %s)" % (bytes_to_human(float(total_memory_bytes_requested)/total_cpus_used),
       	 bytes_to_human(float(total_serial_memory_bytes_requested)/int(serial_jobs_complete)),
       	 bytes_to_human(float(total_mpi_memory_bytes_requested)/int(total_mpi_cpus_used)),
       	 bytes_to_human(float(total_shared_memory_bytes_requested)/int(total_shared_cpus_used)))
    elif total_mpi_memory_bytes_requested > 0 and total_shared_memory_bytes_requested > 0 and total_serial_memory_bytes_requested == 0:
	print "Average memory per job: %s (MPI %s, SM %s)" % (bytes_to_human((float(total_memory_bytes_requested)/int(jobs_complete))),
       	 bytes_to_human(float(total_mpi_memory_bytes_requested)/int(mpi_jobs_complete)),
       	 bytes_to_human(float(total_shared_memory_bytes_requested)/int(shared_jobs_complete)))
	print "Average memory per core: %s (MPI %s, SM %s)" % (bytes_to_human(float(total_memory_bytes_requested)/total_cpus_used),
         bytes_to_human(float(total_mpi_memory_bytes_requested)/int(total_mpi_cpus_used)),
         bytes_to_human(float(total_shared_memory_bytes_requested)/int(total_shared_cpus_used)))
    elif total_serial_memory_bytes_requested > 0 and total_shared_memory_bytes_requested > 0 and total_mpi_memory_bytes_requested == 0:
	print "Average memory per job: %s (serial %s, SM %s)" % (bytes_to_human((float(total_memory_bytes_requested)/int(jobs_complete))),
         bytes_to_human(float(total_serial_memory_bytes_requested)/int(serial_jobs_complete)),
         bytes_to_human(float(total_shared_memory_bytes_requested)/int(shared_jobs_complete)))
        print "Average memory per core: %s (serial %s, SM %s)" % (bytes_to_human(float(total_memory_bytes_requested)/total_cpus_used),
         bytes_to_human(float(total_serial_memory_bytes_requested)/int(serial_jobs_complete)),
         bytes_to_human(float(total_shared_memory_bytes_requested)/int(total_shared_cpus_used)))
    elif total_serial_memory_bytes_requested > 0 and total_mpi_memory_bytes_requested > 0 and total_shared_memory_bytes_requested == 0:
	print "Average memory per job: %s (serial %s, MPI %s)" % (bytes_to_human((float(total_memory_bytes_requested)/int(jobs_complete))),
         bytes_to_human(float(total_serial_memory_bytes_requested)/int(serial_jobs_complete)),
         bytes_to_human(float(total_mpi_memory_bytes_requested)/int(mpi_jobs_complete)))
        print "Average memory per core: %s (serial %s, MPI %s)" % (bytes_to_human(float(total_memory_bytes_requested)/total_cpus_used),
         bytes_to_human(float(total_serial_memory_bytes_requested)/int(serial_jobs_complete)),
         bytes_to_human(float(total_mpi_memory_bytes_requested)/int(total_mpi_cpus_used)))
  
    else:

        print "Average memory per job: %s" % (bytes_to_human((float(total_memory_bytes_requested)/int(jobs_complete))))
        print "Average memory per core: %s" % (bytes_to_human(float(total_memory_bytes_requested)/total_cpus_used))
        print " "
        print "-----------------------------"

#    print "DEBUG"
#    print total_job_time
#    print total_node_hours
#    print users



################################# Main ##################################################

ap = argparse.ArgumentParser()
ap.add_argument("--username","-u",dest="username",action="store",required=False,help="Show only jobs for this username")
ap.add_argument("--queue","-q",dest="queue",action="store",required=False,help="Show only jobs for this queue")
ap.add_argument("--job","-j",dest="job",action="store",required=False,help="Show only this job ID in full")
ap.add_argument("--print-nodes","-n",dest="nodes",action="store_true",required=False,default=False,help="Print full node list used for each job")
ap.add_argument("--files","-f",dest="files",nargs='+',action="store",required=False,help="Use the accounting records in these files",
    default = glob('/var/spool/torque/server_priv/accounting/*'))
ap.add_argument("--statistics","-s",dest="summarize",action="store_true",required=False,default=False,help="Print utilization statistics")
ap.add_argument("--nodestatistics","-z",dest="nodestats",action="store_true",required=False,default=False,help="Print node utilization statistics")
ap.add_argument("--debug","-d",dest="debug",action="store_true",required=False,default=False,help="Print debug information")

args=ap.parse_args()

if args.debug:
    debug = 1

jobs = parser.parse_files(args.files, debug)

if args.job:
    print_full_job(args.job,jobs)
    sys.exit(0)
if args.username:
    jobs=filter_by_user(args.username,jobs)
if args.queue:
    jobs=filter_by_queue(args.queue,jobs)

if args.summarize:
    print_summary(jobs, args.nodestats)
    sys.exit(0)

print_header()
for j in sorted(jobs.iterkeys(),key=jobname_to_int):
    print_job(j,jobs[j])
    if args.nodes:
        print_nodes(jobs[j])


